\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{ACL2 workshop 2018} % Name of the event you are submitting to

%% Todo list
%% Gotta substantiate the co-simulations we talked about...
%% Gotta talk about the number of things we re-used from L6 in M2
%% Gotta de-emphasise the proofs for L1 through L6 - they're OK but
%%  not that important. However, the read-over-write proofs for M1
%%  need to be finished.
%% Gotta substantiate the point about code re-use in CP/M and FAT32 -
%%  obviously there isn't enough time to do anything about ext4
%% (done) Gotta talk about concurrent calls in future work - and
%%  update that whole section with FAT32 stuff assumed done, obviously
%% Gotta substantiate the claim about non-determinism in M1
%% (done) Gotta fix the darned diagram!
%% Gotta address the non-exhaustive set of system calls and their choice
%% Gotta talk about error codes and other things taken from the kernel implementation
%% Gotta do caching and talk about it

\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{matrix}

\usepackage{breakurl}             % Not needed if you use pdflatex only.
\usepackage{underscore}           % Only needed if you use pdflatex.

\title{Formalising filesystems in the ACL2 theorem prover:\\ an
  application to FAT32}
\author{Mihir Parang Mehta
\institute{Department of Computer Science\\
University of Texas at Austin\\
Austin, TX, USA}
\email{mihir@cs.utexas.edu}}
\def\titlerunning{FAT32 formalisation}
\def\authorrunning{M.P. Mehta}
\begin{document}
\maketitle

\begin{abstract}
In this work, we present an
approach towards constructing executable specifications of existing
filesystems and verifying their functional properties in a theorem
proving environment. We detail an application of this approach to the
FAT32 filesystem.

We also detail the methodology used to build up this type of
executable specification through a series of models which
incrementally add features of the target filesystem. This methodology
has the benefit of allowing the verification effort to start from
simple models which encapsulate features common to many filesystems
and which are thus suitable for re-use.
\end{abstract}

\section{Introduction and overview}

Filesystems are ubiquitous in computing, providing application
programs a means to store data persistently, address data by a name
instead of a numeric index, and communicate with other programs.
Thus, the vast majority of application programs
directly or indirectly rely upon filesystems, which makes filesystem
verification critically important. Here, we present a
formalisation effort in ACL2 for an implementation of the FAT32
filesystem, and a proof of the read-over-write properties for this
filesystem. By starting with a high-level abstract model and adding
more filesystem features in successive models, we are able to manage the
complexity of this proof, which has not, to our knowledge, been
previously attempted. Thus, this paper contributes an implementation
of FAT32, a widely-used filesystem, formally verified against an
abstract specification and tested for binary compatibility by means of
co-simulation.

In the rest of this paper, we describe these filesystem
models and the properties proved with examples; we proceed to a
high-level explanation of these proofs and the co-simulation
infrastructure; and further we offer some insights about the low-level
issues encountered while working the proofs.
%% I'm not sure I want to keep the statistics. Certainly ACL2 folks
%% don't want to see them.
%% We end with some statistics pertaining to the magnitude of the
%% proof effort and the running time of the proofs.

\section{Related work}

Filesystem verification research has largely followed a pattern of
synthesising a new filesystem based on a specification chosen for its
ease in proving properties of interest, rather than similarity to an
existing filesystem. Our work, in contrast, follows the FAT32
specification closely. In spirit, our work is closer to previous work
which uses interactive theorem provers and explores deep functional
properties than to efforts which use non-interactive theorem provers
such as Z3 to produce fully automated proofs of simpler properties.

\subsection{Interactive theorem provers}
An early effort in the filesystem verification domain was by Bevier
and Cohen~\cite{bevier1996executable}, who specified the Synergy
filesystem and created an executable model of the same in ACL2
\cite{kaufmann2000}, down to the level of processes
and file descriptors. On the proof front, they certified their model
to preserve well-formedness of their data structures through their
various file operations; however, they did not attempt to prove, for
instance, read-over-write properties or crash consistency. Later,
Klein et al with the SeL4 project~\cite{klein2009sel4} used
Isabelle/HOL~\cite{nipkow2002isabelle} to verify a microkernel;
while their design abstracted away file operations in order to keep
their trusted computing base small, it did serve as a precursor to their
more recent COGENT project~\cite{amani2016cogent}. Here the authors
built a "verified compiler" of sorts, generating C-language code from
specifications in their domain-specific in a manner guaranteed to
avoid many common filesystem bugs. Elsewhere, the SibylFS
project~\cite{ridge2015sibylfs}, again using Isabelle/HOL, provided
an executable specification for filesystems at a level of abstraction
that could function across multiple operating systems including OSX
and Unix. The Coq prover \cite{bertot2013interactive} has also been
used, for instance, for FSCQ
\cite{DBLP:conf/usenix/ChenZCCKZ16}, a state-of-the art filesystem
which was built to have high performance and formally verified crash
consistency properties.

\subsection{Non-interactive theorem provers}
Non-interactive theorem provers such as Z3 \cite{de2008z3}
have also been used; Hyperkernel
\cite{Nelson:2017:HPV:3132747.3132748} is a recent effort which
focusses on simplifying the xv6 microkernel until the point that Z3
can verify it with its SMT solving techniques. However, towards this
end, all system calls in Hyperkernel are replaced with analogs which
can terminate in constant time; while this approach is theoretically
sound, it increases the chances of discrepancies between the model and
the implementation which may diminish the utility of the proofs or
even render them moot. A stronger effort in the same domain is
Yggdrasil~\cite{sigurbjarnarson2016push}, which focusses on verifying
filesystems with the use of Z3. While the authors make substantial
progress in terms of the number of filesystem calls they support and
the crash consistency guarantees they provide, they are subject to
the limits of SMT solving which prevent them from modelling essential
filesystem features such as extents, which are central to many
filesystems including FAT32.

\section{Program architecture and performance considerations}

We number our abstract filesystem models \texttt{L1} through
\texttt{L6}, and our concrete models \texttt{M1} through \texttt{M2}
(concrete). These models are constructed incrementally to allow for
reuse of features in general, and a refinement relation where
possible.

Starting with \texttt{L1}, an abstract model representing the directory
structure as a tree, we add file
metadata in \texttt{L2}. We branch off from \texttt{L2} into
\texttt{L3}, a model with file contents broken up into blocks and
stored in an external disk-like data structure, and \texttt{L4}, a
model which also breaks file contents up into disk blocks,
additionally with garbage collection through reference counting, and a
fixed disk size bounding the total size of file contents. To implement
the reference counter in \texttt{L4}, we use an allocation vector as
in the CP/M filesystem, which happens to be the previous technology
target of this work prior to FAT32. We are able to refine \texttt{L4}
into \texttt{L6}, a filesystem with exactly the same properties but
additionally featuring a FAT32-like file allocation table for
allocation and garbage collection, since this data structure happens
to refine the allocation vector.

\texttt{M1} is another tree model, which hews somewhat closely to the
FAT32 specification; it is also used as the in-memory format for
\texttt{M2}, a real model which reads and writes FAT32 disk
images. The operations currently supported are \texttt{pread(2)},
\texttt{pwrite(2)}, and \texttt{stat(2)}. With these operations, we
are able to model the file operations used in standard disk utilities
such as cat(1) and dd(1), with a view to writing formal specifications
of these programs later.

There is not a refinement relation between the abstract models and the
concrete models, but we re-use many of our theorems from \texttt{L6}
in \texttt{M2} since the file allocation data structure in \texttt{L6}
follows the FAT32 specification.

In order to obtain reasonable execution performance, we implement
\texttt{M2} as a single-threaded object. Most importantly, this allows
us to model the file allocation table and data region, which are long
arrays, as arrays in Common Lisp rather than as lists, which have poor
performance for update operations on their elements because of the
number of cons cells which must be created and garbage collected for
each update. Array operations in single threaded objects are subject
to certain syntactic restrictions to prevent copies of arrays from
being created as usually happens with Lisp objects; to simplify the
task of reading and writing disk images under these restrictions, we
also create a library of useful macros.

We choose to implement a subset of the POSIX filesystem application
programming interface. This allows us to easily compare the results of
running filesystem operations on \texttt{M2} and the Linux kernel's
implementation of FAT32, which in turn allows us to test our
implementation's correctness through co-simulation in addition to
theorem proving. One trade-off for this choice is the necessity of
emulating certain functionality provided by the Linux kernel to all
filesystems; thus, we implement process tables and file tables through
a straightforward approach similar to that used in
Synergy~\cite{bevier1996executable}.

\section{The FAT32 filesystem}

FAT32 was initially developed at Microsoft~\cite{microsoft2000} in
order to address certain shortcomings of the DOS filesystem previously
in use in their operating systems. While it is simple by today's
standards, it does add some complexity compared to the filesystems
which came before.

All files, including regular files and directory files, are divided into
\textit{clusters} (sometimes called \textit{extents}) of a fixed size,
which is decided at the time a FAT32 volume is formatted, and
constrained to be a multiple of the disk sector size. Directory files
differ only in a metadata attribute which indicates that their contents
should be treated as a sequence of directory entries. Each such
directory entry is 32 bytes wide and contains information including
name, size, first cluster index, and access times for the
corresponding file.

The file allocation table itself contains a number of linked lists. It
maps each cluster index used by a file to either the next cluster
index for that file or a special end-of-clusterchain value \footnote{
There is actually a range of end-of-clusterchain values in the
specification, not just one. We support all values in the range.} This
allows the contents of a file to be reconstructed by
reading just the first cluster index from the corresponding directory
entry, and building the list of clusters using the table. Unused
clusters are mapped to 0 in the table; this fact is used for counting
and allocating free clusters.

We illustrate the file allocation table and data layout for a small
example directory tree in figure~\ref{fat32-example}. It should be
noted that the \texttt{/tmp} directory is part of the root filesystem
here, unlike in some operating systems where \texttt{/tmp} is the
mountpoint for a different filesystem; also, for the purposes of
illustration, all regular files and directories are assumed to span
one cluster except for \texttt{/vmlinuz} which spans two clusters.

\begin{figure}
  \centering
  \caption{A FAT32 directory tree}
  \label{fat32-example}
  \begin{tikzpicture}[sibling distance=5em,
      every node/.style = {shape=rectangle, rounded corners,
        draw, align=center,
        top color=white, bottom color=violet!20}]
    \node {/}
    child { node {vmlinuz}}
    child { node {initrd.img}}
    child { node {tmp/}
      child { node {ticket1.txt}}
      child { node {ticket2.txt}}};
  \end{tikzpicture}

  \begin{tabular}{|c|c|}
    \hline
    FAT index & FAT entry \\ \hline
    0 (unused) &  \\ \hline
    1 (unused) &  \\ \hline
    2 & \textit{EOC} \\ \hline
    3 & 4 \\ \hline
    4 & \textit{EOC} \\ \hline
    5 & \textit{EOC} \\ \hline
    6 & \textit{EOC} \\ \hline
    7 & \textit{EOC} \\ \hline
    8 & \textit{EOC} \\ \hline
    9 & 0 \\ \hline
    \vdots & \vdots
  \end{tabular}\\

  \begin{tabular}{|c|c|}
    \hline
       & Directory entry in / \\ \hline
    0  & "vmlinuz", 3 \\ \hline
    32 & "initrd.img", 5 \\ \hline
    64 & "tmp", 6 \\ \hline
    \vdots & \vdots
  \end{tabular}

  \begin{tabular}{|c|c|}
    \hline
       & Directory entry in /tmp/ \\ \hline
    0  & "ticket1", 7 \\ \hline
    32 & "ticket2", 8 \\ \hline
    \vdots & \vdots
  \end{tabular}
\end{figure}

%% \begin{figure}
%%   \includegraphics[page=1,width=1.10\textwidth]{fat32-diagram.pdf}
%% \end{figure}

\section{The models}

For every read or write operation, FAT32 requires one or more lookups
into the file allocation table, followed by the corresponding lookups
into the data region. This makes proof efforts about these operations
complex, which serves as the motivation for modelling the filesystem
in a series of steps.

\begin{table}[]
  \centering
  \caption{Abstract models and their features}
  \label{abstract-model-description-table}
  \begin{tabular}{|l|p{120mm}|}
    \hline
    \texttt{L1} & The filesystem is represented as a tree, with leaf
    nodes for regular files and non-leaf nodes for
    directories. The contents of regular files are represented as
    strings stored in the nodes of the tree; the storage available for
    these is unbounded. \\ \hline
    \texttt{L2} & A single element of metadata, \textit{length}, is
    stored within each regular file.  \\ \hline
    \texttt{L3} & The contents of regular files are divided into
    blocks of fixed size. These blocks are stored in an external
    "disk" data structure; the storage for these blocks remains
    unbounded. \\ \hline
    \texttt{L4} & The storage available for blocks is now bounded. An
    allocation vector data structure is introduced to help allocate
    and garbage collect blocks. \\ \hline
    \texttt{L5} & Additional metadata for file ownership and access
    permissions is stored within each regular file. \\ \hline
    \texttt{L6} & The allocation vector is replaced by a file
    allocation table, matching the official FAT specification. \\ \hline
  \end{tabular}
\end{table}

\begin{table}[]
  \centering
  \caption{Concrete models}
  \label{concrete-model-description-table}
  \begin{tabular}{|l|p{120mm}|}
    \hline
    \texttt{M1} & The filesystem is represented as a tree, as in
    \texttt{L1}. Write operations show non-determinism in order to
    model disk capacity errors in a real filesystem. \\ \hline
    \texttt{M2} & A single element of metadata, \textit{length}, is
    stored within each regular file.  \\ \hline
  \end{tabular}
\end{table}

\begin{figure}
  \centering
  \caption{Refinement relationships between models}
  \label{refinement-figure}
  \begin{tikzpicture}[sibling distance=15em,
      every node/.style = {shape=rectangle, rounded corners,
        draw, align=center,
        top color=white, bottom color=blue!20}]
    \node {L1 - tree}
    child { node {L2 - length}
      child { node {L3 - unbounded disk}}
      child { node {L4 - bounded disk with garbage collection}
        child { node {L5 - permissions}}
        child { node {L6 - file allocation table}}}};
  \end{tikzpicture}
\end{figure}

At this point in development, we have six models of the filesystem,
here referred to as \texttt{L1} through \texttt{L6}, described in
table \ref{abstract-model-description-table}. Each model other than
\texttt{L1}
refines a previous model, adding some features and complexity and
thereby approaching closer to a model which is binary compatible with
FAT32. These refinement relationships are shown in figure
\ref{refinement-figure}. \texttt{L1} is the simplest of these,
representing the filesystem as a literal directory tree; later models
feature file metadata (including ownership and permissions),
externalisation of file contents, and allocation/file allocation using
an allocation vector after the fashion of the CP/M file system (this
is a remnant of an earlier filesystem verification effort for CP/M,
which we subsumed into the present work).

Broadly, we characterise the filesystem
operations we offer as either \textit{write} operations, which do
modify the filesystem, or \textit{read} operations, which do not. In
each model, we have been able to prove \textit{read-over-write}
properties which show that write operations have
their effects made available immediately for reads at the same
location, but also that they do not affect reads at other locations.

The first read-after-write theorem states that immediately following a
write of some text at some location, a read of the same length at the
same location yields the same text. The second read-after-write
theorem states that after a write of some text at some location, a
read at any other location returns exactly what it would have returned
before the write. As an example, listings for the \texttt{L1} versions
of these theorems follow.

\medskip

\noindent
\begin{verbatim}
(defthm l1-read-after-write-1
  (implies (and (l1-fs-p fs)
                (stringp text)
                (symbol-listp hns)
                (natp start)
                (equal n (length text))
                (stringp (l1-stat hns fs)))
           (equal (l1-rdchs hns (l1-wrchs hns fs start text) start n) text)))

(defthm l1-read-after-write-2
  (implies (and (l1-fs-p fs)
                (stringp text2)
                (symbol-listp hns1)
                (symbol-listp hns2)
                (not (equal hns1 hns2))
                (natp start1)
                (natp start2)
                (natp n1)
                (stringp (l1-stat hns1 fs)))
           (equal (l1-rdchs hns1 (l1-wrchs hns2 fs start2 text2) start1 n1)
                  (l1-rdchs hns1 fs start1 n1))))
\end{verbatim}

By composing these properties, we can reason about executions
involving multiple reads and writes, as illustrated in the following
throwaway proof.

\medskip

\noindent
\begin{verbatim}
(thm
 (implies (and (l1-fs-p fs)
               (stringp text1)
               (stringp text2)
               (symbol-listp hns1)
               (symbol-listp hns2)
               (not (equal hns1 hns2))
               (natp start1)
               (natp start2)
               (stringp (l1-stat hns1 fs))
               (equal n1 (length text1)))
          (equal (l1-rdchs hns1
                           (l1-wrchs hns2 (l1-wrchs hns1 fs start1 text1)
                                     start2 text2)
                           start1 n1)
                 (l1-rdchs hns1 (l1-wrchs hns1 fs start1 text1)
                           start1 n1))))
\end{verbatim}

\section{Proof methodology}

In \texttt{L1}, our simplest model, the read-over-write properties
were, of necessity, proven from scratch.

In each subsequent model, the read-over-write properties are proven as
corollaries of equivalence proofs which establish the correctness of
read and write operations in the respective model with respect to a
previous model. A representation of such an equivalence proof can be
seen in figures \ref{l2-wrchs-correctness-1},
\ref{l2-rdchs-correctness-1} and \ref{l2-read-over-write-1}, which
respectively show the equivalence proof for \texttt{l2-wrchs}, the
equivalence proof for \texttt{l2-rdchs} and the composition of these
to obtain the first read-over-write theorem for model \texttt{L2}.


\begin{figure}
  \centering
  \caption{l2-wrchs-correctness-1}
  \label{l2-wrchs-correctness-1}
  \begin{tikzpicture}
    \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
            {
              l2 & l2 \\
              l1 & l1 \\};
            \path[-stealth]
            (m-1-1) edge node [left] {l2-to-l1-fs} (m-2-1)
            edge node [below] {write} (m-1-2)
            (m-2-1.east|-m-2-2) edge node [below] {write} (m-2-2)
            (m-1-2) edge node [left] {l2-to-l1-fs} (m-2-2);
  \end{tikzpicture}
\end{figure}

\begin{figure}
  \centering
  \caption{l2-rdchs-correctness-1}
  \label{l2-rdchs-correctness-1}
  \begin{tikzpicture}
    \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
            {
              l2 & text \\
              l1 \\};
            \path[-stealth]
            (m-1-1) edge node [left] {l2-to-l1-fs} (m-2-1)
            edge node [below] {read} (m-1-2)
            (m-2-1.east|-m-2-2) edge node [below] {read} (m-1-2);
  \end{tikzpicture}
\end{figure}

\begin{figure}
  \centering
  \caption{l2-read-over-write-1}
  \label{l2-read-over-write-1}
  \begin{tikzpicture}
    \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
            {
              l2 & l2 & text \\
              l1 & l1 \\};
            \path[-stealth]
            (m-1-1) edge node [left] {l2-to-l1-fs} (m-2-1)
            edge node [below] {write} (m-1-2)
            (m-2-1.east|-m-2-2) edge node [below] {write} (m-2-2)
            (m-1-2) edge node [left] {l2-to-l1-fs} (m-2-2)
            edge node [below] {read} (m-1-3)
            (m-2-2.east) edge node [below] {read} (m-1-3);
  \end{tikzpicture}
\end{figure}

\section{Some proof details}

We have come to rely on certain principles for the proof effort for
each new model. We summarise these below.

\subsection{Invariants}

As the models grow more complex, with the addition of more auxiliary
data the "sanity" criteria for filesystem instances become more
complex. For instance, in \texttt{L4}, the predicate \texttt{l4-fs-p}
is defined to be the same as \texttt{l3-fs-p}, which recursively
defines the shape of a valid directory tree. However, we choose to
require two more properties for a "sane" filesystem.

\begin{enumerate}
\item Each disk index assigned to a regular file should be
  marked as \textit{used} in the allocation vector - this is essential
  to prevent filesystem errors.
\item Each disk index assigned to a regular file should be distinct
  from all other disk indices assigned to files - this does not hold
  true, for example, in filesystems with hardlinks, but makes our
  proofs easier.
\end{enumerate}

These properties are invariants to be maintained across
write operations; while not all of them are strictly necessary for a
filesystem instance to be valid, they do simplify the verification of
read-after-write properties by helping us ensure that write operations
do not create an "aliasing" situation in which a regular file's
contents can be modified through a write to a different regular file.

These properties, in the form of the predicates
\texttt{indices-marked-listp} and \texttt{no-duplicatesp}, are
packaged together into the \texttt{l4-stricter-fs-p} predicate, for
which a listing follows.

\medskip

\noindent
\begin{verbatim}
(defun l4-stricter-fs-p (fs alv)
  (declare (xargs :guard t))
  (and (l4-fs-p fs)
       (boolean-listp alv)
       (let ((all-indices (l4-list-all-indices fs)))
            (and (no-duplicatesp all-indices)
                 (indices-marked-p all-indices alv)))))
\end{verbatim}

\subsection{Reuse}

As noted earlier, using a refinement methodology allows us to derive
our read-over-write properties essentially "for free"; more precisely,
we are able to prove read-over-write properties simply with
\texttt{:use} hints after having done the work of proving refinement
through induction.

At a lower level, we are also able to benefit from refinement
relationships between components of our different models. For example,
such a relationship exists between the allocation vector used in
\texttt{L4} and the file allocation table used in \texttt{L6}. More
precisely, by taking a file allocation table and mapping each non-zero
entry to \texttt{true} and each zero entry to \texttt{false}, we
obtain a corresponding allocation vector with exactly the same amount
of available space. This is a refinement mapping which makes it a lot
easier to prove that \texttt{L4}, which uses an allocation vector, is
an abstraction of \texttt{L6}, which uses a file allocation
table. This, in turn, means that the effort spent on proving the
invariants described above for \texttt{L4} need not be replicated for
\texttt{L6}.

\section{Co-simulation}

Previous work on executable specifications \cite{goel2014simulation}
has shown the importance of testing these on real examples, in order
to validate that the behaviour shown matches that of the system being
specified. In our case, this means we must validate our filesystem by
testing it in execution against a canonical implementation of FAT32;
in this case, we choose the implementation which ships with Linux
kernel 3.10.

We use \texttt{mkfs.fat}~\cite{hudsonmkfs}, a program which produces
FAT32 disk images, for our tests. When run with the \texttt{-v} flag,
this program emits an English-language summary of the fields of the
newly created disk image; we make use of this by writing an ACL2
program based on our model which reads the image and reproduces this
summary. This validates our code for reading the various fields of the
disk image and gives us a regression test to use while we modify our
model to support proofs and filesystem calls.

%% This stuff is not yet implemented exactly as described.
Our first co-simulation test is for \texttt{cat}~\cite{granlundcat}, a
simple program which reads its input and copies it to its output. Its
functionality is reproduced in an ACL2 program which uses our
implementations of the system calls
\texttt{lstat}~\cite{kerrisklstat},
\texttt{open}~\cite{kerriskopen}, \texttt{pread}~\cite{kerriskpread},
\texttt{pwrite}~\cite{kerriskpwrite}, and
\texttt{close}~\cite{kerriskclose}. This allows us to validate our
code for reading and writing regular files and directories which span
multiple clusters.

%% This stuff is not yet implemented at all.
We further test the \texttt{dd}~\cite{rubindd} program, which provides
similar functionality to \texttt{cat} but with more options to
customise the data transfer, for instance, by allowing the data
transfer to be split into blocks of a specified size.

\section{Conclusion}

This work formalises a FAT32-like filesystem and proves
read-over-write properties through refinement of a series of
models. Further, it proves the correctness of FAT32's allocation and
garbage collection mechanisms, and provides artefacts to be used in a
subsequent realistic model of FAT32.

\section{Future work}

While FAT32 is interesting of and by itself, it lacks features such as
crash consistency, which most modern filesystems provide by means of
journalling. We hope to re-use some artefacts of formalising FAT32 in
order to verify a filesystem with journalling, such as ext4.

We also hope to model the behaviour of filesystems in a
multiprogramming environment, where concurrent filesystem calls must
be able to occur without corruption or loss of data.
%% Also, we hope to support "code proofs", by providing a basis for
%% reasoning about filesystem operations in filesystem-specific utilities
%% such as \texttt{fsck}, as well as other application programs. This is
%% a large part of the motivation for pursuing binary compatibility.

\subsubsection*{Acknowledgments.} This material is based upon work
supported by the National Science Foundation SaTC program under
contract number CNS-1525472. Thanks are also due to Warren A. Hunt
Jr. and Matthew J. Kaufmann for their guidance.

\section{Bibliography}

\bibliographystyle{eptcs}
\bibliography{references}
\end{document}
