\documentclass[submission,copyright,creativecommons]{eptcs}
\providecommand{\event}{ACL2 workshop 2018} % Name of the event you are submitting to

%% Todo list
%% Gotta substantiate the co-simulations we talked about...
%% Gotta talk about the number of things we re-used from L6 in M2
%% Gotta de-emphasise the proofs for L1 through L6 - they're OK but
%%  not that important.
%% Gotta talk about FTY.
%% Gotta substantiate the point about code re-use in CP/M and FAT32 -
%%  obviously there isn't enough time to do anything about ext4
%% (done) Gotta talk about concurrent calls in future work - and
%%  update that whole section with FAT32 stuff assumed done, obviously
%% Gotta substantiate the claim about non-determinism in M1
%% (done) Gotta fix the darned diagram!
%% Gotta address the non-exhaustive set of system calls and their choice
%% Gotta talk about error codes and other things taken from the kernel implementation
%% Gotta talk about caching (in terms of the M1 tree)
%% Gotta consider renaming L1...L6 to N1...N6

\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{matrix}

\usepackage{breakurl}             % Not needed if you use pdflatex only.
\usepackage{underscore}           % Only needed if you use pdflatex.

\title{Formalising filesystems in the ACL2 theorem prover:\\ an
  application to FAT32}
\author{Mihir Parang Mehta
\institute{Department of Computer Science\\
University of Texas at Austin\\
Austin, TX, USA}
\email{mihir@cs.utexas.edu}}
\def\titlerunning{FAT32 formalisation}
\def\authorrunning{M.P. Mehta}
\begin{document}
\maketitle

\begin{abstract}
In this work, we present an
approach towards constructing executable specifications of existing
filesystems and verifying their functional properties in a theorem
proving environment. We detail an application of this approach to the
FAT32 filesystem.

We also detail the methodology used to build up this type of
executable specification through a series of models which
incrementally add features of the target filesystem. This methodology
has the benefit of allowing the verification effort to start from
simple models which encapsulate features common to many filesystems
and which are thus suitable for re-use.
\end{abstract}

\section{Introduction and overview}

Filesystems are ubiquitous in computing, providing application
programs a means to store data persistently, address data by a name
instead of a numeric index, and communicate with other programs.
Thus, the vast majority of application programs
directly or indirectly rely upon filesystems, which makes filesystem
verification critically important. Here, we present a
formalisation effort in ACL2 for the FAT32 filesystem, and a proof of
the read-over-write properties for FAT32 system calls. By starting
with a high-level abstract model and adding more filesystem features
in successive models, we are able to manage the complexity of this
proof, which has not, to our knowledge, been previously
attempted. Thus, this paper contributes an implementation of several
Unix-like system calls for FAT32, formally verified against an
abstract specification and tested for binary compatibility by means of
co-simulation.

In the rest of this paper, we describe these filesystem
models and the properties proved, with examples; we proceed to a
high-level explanation of these proofs and the co-simulation
infrastructure; and further we offer some insights about the low-level
issues encountered while working the proofs.
%% I'm not sure I want to keep the statistics. Certainly ACL2 folks
%% don't want to see them.
%% We end with some statistics pertaining to the magnitude of the
%% proof effort and the running time of the proofs.

\section{Related work}

Filesystem verification research has largely followed a pattern of
synthesising a new filesystem based on a specification chosen for its
ease in proving properties of interest, rather than similarity to an
existing filesystem. Our work, in contrast, follows the FAT32
specification closely. In spirit, our work is closer to previous work
which uses interactive theorem provers and explores deep functional
properties than to efforts which use non-interactive theorem provers
such as Z3 to produce fully automated proofs of simpler properties.

\subsection{Interactive theorem provers}
An early effort in the filesystem verification domain was by Bevier
and Cohen~\cite{bevier1996executable}, who specified the Synergy
filesystem and created an executable model of the same in ACL2
\cite{kaufmann2000}, down to the level of processes
and file descriptors. On the proof front, they certified their model
to preserve well-formedness of their data structures through their
various file operations; however, they did not attempt to prove, for
instance, read-over-write properties or crash consistency. Later,
Klein et al with the SeL4 project~\cite{klein2009sel4} used
Isabelle/HOL~\cite{nipkow2002isabelle} to verify a microkernel;
while their design abstracted away file operations in order to keep
their trusted computing base small, it did serve as a precursor to their
more recent COGENT project~\cite{amani2016cogent}. Here the authors
built a verifying compiler to translate a filesystem specification in
their domain-specific language to C-language code, accompanied by
a proof of the correctness of this translation. Elsewhere, the SibylFS
project~\cite{ridge2015sibylfs}, again using Isabelle/HOL, provided
an executable specification for filesystems at a level of abstraction
that could function across multiple operating systems including OSX
and Unix. The Coq prover \cite{bertot2013interactive} has also been
used, for instance, for FSCQ
\cite{DBLP:conf/usenix/ChenZCCKZ16}, a state-of-the art filesystem
which was built to have high performance and formally verified crash
consistency properties.

\subsection{Non-interactive theorem provers}
Non-interactive theorem provers such as Z3 \cite{de2008z3}
have also been used; Hyperkernel
\cite{Nelson:2017:HPV:3132747.3132748} is a recent effort which
simplifies the xv6~\cite{cox6xv6} microkernel until the
point where Z3 can verify its properties with its SMT solving
techniques. However, towards this end, all system calls in Hyperkernel
are replaced with analogs which can terminate in constant time; while
this approach is theoretically sound, it increases the chances of
discrepancies between the model and
the implementation which may diminish the utility of the proofs or
even render them moot. A stronger effort in the same domain is
Yggdrasil~\cite{sigurbjarnarson2016push}, which focusses on verifying
filesystems with the use of Z3. While the authors make substantial
progress in terms of the number of filesystem calls they support and
the crash consistency guarantees they provide, they are subject to
the limits of SMT solving which prevent them from modelling filesystem
features such as extents, which are essential to FAT32 and many other
filesystems.

\section{Program architecture and performance considerations}

We have two concrete models for the FAT32 filesystem - \texttt{M2},
which is a faithful representation of a FAT32 disk image in the form
of a stobj~\cite{boyer2002single}, and \texttt{M1}, which represents the
state of the FAT32 filesystem as a directory tree. This allows us to
address the practical details of updating a disk image in \texttt{M2},
which benefits from ACL2's efficient stobj array operations provides
for stobjs, and abstract them away in \texttt{M1} for easier reasoning
without the syntactic constraints imposed on stobj arrays.

These concrete filesystem models are based upon abstract models
\texttt{L1} through \texttt{L6}. These models are constructed
incrementally to allow for reuse of features in general, and
refinement relations where necessary for proofs. Much of the code and
proof infrastructure is also shared between the abstract models and
the concrete models by design, although there is not a formal
refinement relation between the latter and the former. Details of the
filesystem features and refinement/reuse relationships between the
abstract models can be seen in table
\ref{abstract-model-description-table} and figure
\ref{refinement-figure} respectively.

\begin{table}[]
  \centering
  \caption{Abstract models and their features}
  \label{abstract-model-description-table}
  \begin{tabular}{|l|p{120mm}|}
    \hline
    \texttt{L1} & The filesystem is represented as a tree, with leaf
    nodes for regular files and non-leaf nodes for
    directories. The contents of regular files are represented as
    strings stored in the nodes of the tree; the storage available for
    these is unbounded. \\ \hline
    \texttt{L2} & A single element of metadata, \textit{length}, is
    stored within each regular file.  \\ \hline
    \texttt{L3} & The contents of regular files are divided into
    blocks of fixed size. These blocks are stored in an external
    "disk" data structure; the storage for these blocks remains
    unbounded. \\ \hline
    \texttt{L4} & The storage available for blocks is now bounded. An
    allocation vector data structure is introduced to help allocate
    and garbage collect blocks. \\ \hline
    \texttt{L5} & Additional metadata for file ownership and access
    permissions is stored within each regular file. \\ \hline
    \texttt{L6} & The allocation vector is replaced by a file
    allocation table, matching the official FAT specification. \\ \hline
  \end{tabular}
\end{table}

\begin{figure}
  \centering
  \caption{Refinement/reuse relationships between abstract models}
  \label{refinement-figure}
  \begin{tikzpicture}[sibling distance=15em,
      every node/.style = {shape=rectangle, rounded corners,
        draw, align=center,
        top color=white, bottom color=blue!20}]
    \node {L1 - tree}
    child { node {L2 - length}
      child { node {L3 - unbounded disk}}
      child { node {L4 - bounded disk with garbage collection}
        child { node {L5 - permissions}}
        child { node {L6 - file allocation table}}}};
  \end{tikzpicture}
\end{figure}

%% Starting with \texttt{L1}, an abstract model representing the directory
%% structure as a tree, we add file
%% metadata in \texttt{L2}. We branch off from \texttt{L2} into
%% \texttt{L3}, a model with file contents broken up into blocks and
%% stored in an external disk-like data structure, and \texttt{L4}, a
%% model which also breaks file contents up into disk blocks,
%% additionally with garbage collection through reference counting, and a
%% fixed disk size bounding the total size of file contents. To implement
%% the reference counter in \texttt{L4}, we use an allocation vector as
%% in the CP/M filesystem, which happens to be the previous technology
%% target of this work prior to FAT32. We are able to refine \texttt{L4}
%% into \texttt{L6}, a filesystem with exactly the same properties but
%% additionally featuring a FAT32-like file allocation table for
%% allocation and garbage collection, since this data structure happens
%% to refine the allocation vector.

%% \texttt{M1} is another tree model, which hews somewhat closely to the
%% FAT32 specification; it is also used as the in-memory format for
%% \texttt{M2}, a real model which reads and writes FAT32 disk
%% images. The operations currently supported are \texttt{pread(2)},
%% \texttt{pwrite(2)}, and \texttt{stat(2)}. With these operations, we
%% are able to model the file operations used in standard disk utilities
%% such as cat(1) and dd(1), with a view to writing formal specifications
%% of these programs later.

%% There is not a refinement relation between the abstract models and the
%% concrete models, but we re-use many of our theorems from \texttt{L6}
%% in \texttt{M2} since the file allocation data structure in \texttt{L6}
%% follows the FAT32 specification.

%% In order to obtain reasonable execution performance, we implement
%% \texttt{M2} as a single-threaded object. Most importantly, this allows
%% us to model the file allocation table and data region, which are long
%% arrays, as arrays in Common Lisp rather than as lists, which have poor
%% performance for update operations on their elements because of the
%% number of cons cells which must be created and garbage collected for
%% each update. Array operations in single threaded objects are subject
%% to certain syntactic restrictions to prevent copies of arrays from
%% being created as usually happens with Lisp objects; to simplify the
%% task of reading and writing disk images under these restrictions, we
%% also create a library of useful macros.

We choose to implement a subset of the POSIX filesystem application
programming interface. This allows us to easily compare the results of
running filesystem operations on \texttt{M2} and the Linux kernel's
implementation of FAT32, which in turn allows us to test our
implementation's correctness through co-simulation in addition to
theorem proving. One trade-off for this choice is the necessity of
emulating certain functionality provided by the Linux kernel to all
filesystems; thus, we implement process tables and file tables through
a straightforward approach similar to that used in
Synergy~\cite{bevier1996executable}.

\section{The FAT32 filesystem}

FAT32 was initially developed at Microsoft in order to address the
capacity constraints of the DOS filesystem. Microsoft's specification
for FAT32~\cite{microsoft2000} details the data layout and constraints
for valid FAT32 disk images.

In FAT32 all files, including regular files and directory files, are
divided into \textit{clusters} (sometimes called \textit{extents}) of
a fixed size. The size of a cluster, like many other parameters
of a FAT32 volume, is stored in the \textit{reserved area} of the
volume and remains constant after the volume is created. Directory
files are for the most part treated the same way as regular files by
the filesystem, but they differ in a metadata attribute, which
indicates that the contents of directory files should be treated as
sequences of directory entries. Each such directory entry is
32 bytes wide and contains metadata including name, size, first
cluster index, and access times for the corresponding file.

The file allocation table itself contains a number of linked lists. It
maps each cluster index used by a file to either the next cluster
index for that file or a special end-of-clusterchain value \footnote{
There is actually a range of end-of-clusterchain values in the
specification, not just one. We support all values in the range.} This
allows the contents of a file to be reconstructed by
reading just the first cluster index from the corresponding directory
entry, and building the list of clusters using the table. Unused
clusters are mapped to 0 in the table; this fact is used for counting
and allocating free clusters.

We illustrate the file allocation table and data layout for a small
example directory tree in figure~\ref{fat32-example}. Here,
\texttt{/tmp} is a subdirectory of the root directory
(/texttt{//}). For the purposes of illustration, all regular files and
directories in this example are assumed to span one cluster except for
\texttt{/vmlinuz} which spans two clusters ($3$ and $4$), and
\textit{EOC} refers to an "end of clusterchain" value.

\begin{figure}
  \centering
  \caption{A FAT32 directory tree}
  \label{fat32-example}
  \begin{tikzpicture}[sibling distance=5em,
      every node/.style = {shape=rectangle, rounded corners,
        draw, align=center,
        top color=white, bottom color=violet!20}]
    \node {/}
    child { node {vmlinuz}}
    child { node {initrd.img}}
    child { node {tmp/}
      child { node {ticket1.txt}}
      child { node {ticket2.txt}}};
  \end{tikzpicture}

  \begin{tabular}{|c|c|}
    \hline
    FAT index & FAT entry \\ \hline
    0 (unused) &  \\ \hline
    1 (unused) &  \\ \hline
    2 & \textit{EOC} \\ \hline
    3 & 4 \\ \hline
    4 & \textit{EOC} \\ \hline
    5 & \textit{EOC} \\ \hline
    6 & \textit{EOC} \\ \hline
    7 & \textit{EOC} \\ \hline
    8 & \textit{EOC} \\ \hline
    9 & 0 \\ \hline
    \vdots & \vdots
  \end{tabular}\\

  \begin{tabular}{|c|c|}
    \hline
       & Directory entry in / \\ \hline
    0  & "vmlinuz", 3 \\ \hline
    32 & "initrd.img", 5 \\ \hline
    64 & "tmp", 6 \\ \hline
    \vdots & \vdots
  \end{tabular}

  \begin{tabular}{|c|c|}
    \hline
       & Directory entry in /tmp/ \\ \hline
    0  & "ticket1", 7 \\ \hline
    32 & "ticket2", 8 \\ \hline
    \vdots & \vdots
  \end{tabular}
\end{figure}

%% \section{The models}

%% For every read or write operation, FAT32 requires one or more lookups
%% into the file allocation table, followed by the corresponding lookups
%% into the data region. This makes proof efforts about these operations
%% complex, which serves as the motivation for modelling the filesystem
%% in a series of steps.

%% \begin{table}[]
%%   \centering
%%   \caption{Abstract models and their features}
%%   \label{abstract-model-description-table}
%%   \begin{tabular}{|l|p{120mm}|}
%%     \hline
%%     \texttt{L1} & The filesystem is represented as a tree, with leaf
%%     nodes for regular files and non-leaf nodes for
%%     directories. The contents of regular files are represented as
%%     strings stored in the nodes of the tree; the storage available for
%%     these is unbounded. \\ \hline
%%     \texttt{L2} & A single element of metadata, \textit{length}, is
%%     stored within each regular file.  \\ \hline
%%     \texttt{L3} & The contents of regular files are divided into
%%     blocks of fixed size. These blocks are stored in an external
%%     "disk" data structure; the storage for these blocks remains
%%     unbounded. \\ \hline
%%     \texttt{L4} & The storage available for blocks is now bounded. An
%%     allocation vector data structure is introduced to help allocate
%%     and garbage collect blocks. \\ \hline
%%     \texttt{L5} & Additional metadata for file ownership and access
%%     permissions is stored within each regular file. \\ \hline
%%     \texttt{L6} & The allocation vector is replaced by a file
%%     allocation table, matching the official FAT specification. \\ \hline
%%   \end{tabular}
%% \end{table}

%% \begin{table}[]
%%   \centering
%%   \caption{Concrete models}
%%   \label{concrete-model-description-table}
%%   \begin{tabular}{|l|p{120mm}|}
%%     \hline
%%     \texttt{M1} & The filesystem is represented as a tree, as in
%%     \texttt{L1}. Write operations show non-determinism in order to
%%     model disk capacity errors in a real filesystem. \\ \hline
%%     \texttt{M2} & A single element of metadata, \textit{length}, is
%%     stored within each regular file.  \\ \hline
%%   \end{tabular}
%% \end{table}

%% \begin{figure}
%%   \centering
%%   \caption{Refinement relationships between models}
%%   \label{refinement-figure}
%%   \begin{tikzpicture}[sibling distance=15em,
%%       every node/.style = {shape=rectangle, rounded corners,
%%         draw, align=center,
%%         top color=white, bottom color=blue!20}]
%%     \node {L1 - tree}
%%     child { node {L2 - length}
%%       child { node {L3 - unbounded disk}}
%%       child { node {L4 - bounded disk with garbage collection}
%%         child { node {L5 - permissions}}
%%         child { node {L6 - file allocation table}}}};
%%   \end{tikzpicture}
%% \end{figure}

%% At this point in development, we have six models of the filesystem,
%% here referred to as \texttt{L1} through \texttt{L6}, described in
%% table \ref{abstract-model-description-table}. Each model other than
%% \texttt{L1}
%% refines a previous model, adding some features and complexity and
%% thereby approaching closer to a model which is binary compatible with
%% FAT32. These refinement relationships are shown in figure
%% \ref{refinement-figure}. \texttt{L1} is the simplest of these,
%% representing the filesystem as a literal directory tree; later models
%% feature file metadata (including ownership and permissions),
%% externalisation of file contents, and allocation/file allocation using
%% an allocation vector after the fashion of the CP/M file system (this
%% is a remnant of an earlier filesystem verification effort for CP/M,
%% which we subsumed into the present work).


\section{Proof methodology}

Broadly, we characterise the filesystem
operations we offer as either \textit{write} operations, which do
modify the filesystem, or \textit{read} operations, which do not. In
each model, we have been able to prove \textit{read-over-write}
properties which show that write operations have
their effects made available immediately for reads at the same
location, but also that they do not affect reads at other locations.

The first read-after-write theorem states that immediately following a
write of some text at some location, a read of the same length at the
same location yields the same text. The second read-after-write
theorem states that after a write of some text at some location, a
read at any other location returns exactly what it would have returned
before the write. As an example, listings for the \texttt{L1} versions
of these theorems follow.

\medskip

\noindent
\begin{verbatim}
(defthm l1-read-after-write-1
  (implies (and (l1-fs-p fs)
                (stringp text)
                (symbol-listp hns)
                (natp start)
                (equal n (length text))
                (stringp (l1-stat hns fs)))
           (equal (l1-rdchs hns (l1-wrchs hns fs start text) start n) text)))

(defthm l1-read-after-write-2
  (implies (and (l1-fs-p fs)
                (stringp text2)
                (symbol-listp hns1)
                (symbol-listp hns2)
                (not (equal hns1 hns2))
                (natp start1)
                (natp start2)
                (natp n1)
                (stringp (l1-stat hns1 fs)))
           (equal (l1-rdchs hns1 (l1-wrchs hns2 fs start2 text2) start1 n1)
                  (l1-rdchs hns1 fs start1 n1))))
\end{verbatim}

By composing these properties, we can reason about executions
involving multiple reads and writes, as illustrated in the following
throwaway proof.

\medskip

\noindent
\begin{verbatim}
(thm
 (implies (and (l1-fs-p fs)
               (stringp text1)
               (stringp text2)
               (symbol-listp hns1)
               (symbol-listp hns2)
               (not (equal hns1 hns2))
               (natp start1)
               (natp start2)
               (stringp (l1-stat hns1 fs))
               (equal n1 (length text1)))
          (equal (l1-rdchs hns1
                           (l1-wrchs hns2 (l1-wrchs hns1 fs start1 text1)
                                     start2 text2)
                           start1 n1)
                 (l1-rdchs hns1 (l1-wrchs hns1 fs start1 text1)
                           start1 n1))))
\end{verbatim}

In \texttt{L1}, our simplest model, the read-over-write properties
are proven from scratch. In each subsequent model, the read-over-write
properties are proven as corollaries of equivalence proofs which
establish the correctness of read and write operations in the
respective model with respect to a previous model. A representation of
such an equivalence proof can be seen in figures
\ref{l2-wrchs-correctness-1}, \ref{l2-rdchs-correctness-1} and
\ref{l2-read-over-write-1}, which respectively show the equivalence
proof for \texttt{l2-wrchs}, the equivalence proof for
\texttt{l2-rdchs} and the composition of these to obtain the first
read-over-write theorem for model \texttt{L2}.

\begin{figure}
  \centering
  \caption{l2-wrchs-correctness-1}
  \label{l2-wrchs-correctness-1}
  \begin{tikzpicture}
    \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
            {
              l2 & l2 \\
              l1 & l1 \\};
            \path[-stealth]
            (m-1-1) edge node [left] {l2-to-l1-fs} (m-2-1)
            edge node [below] {write} (m-1-2)
            (m-2-1.east|-m-2-2) edge node [below] {write} (m-2-2)
            (m-1-2) edge node [left] {l2-to-l1-fs} (m-2-2);
  \end{tikzpicture}
\end{figure}

\begin{figure}
  \centering
  \caption{l2-rdchs-correctness-1}
  \label{l2-rdchs-correctness-1}
  \begin{tikzpicture}
    \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
            {
              l2 & text \\
              l1 \\};
            \path[-stealth]
            (m-1-1) edge node [left] {l2-to-l1-fs} (m-2-1)
            edge node [below] {read} (m-1-2)
            (m-2-1.east|-m-2-2) edge node [below] {read} (m-1-2);
  \end{tikzpicture}
\end{figure}

\begin{figure}
  \centering
  \caption{l2-read-over-write-1}
  \label{l2-read-over-write-1}
  \begin{tikzpicture}
    \matrix (m) [matrix of math nodes,row sep=3em,column sep=4em,minimum width=2em]
            {
              l2 & l2 & text \\
              l1 & l1 \\};
            \path[-stealth]
            (m-1-1) edge node [left] {l2-to-l1-fs} (m-2-1)
            edge node [below] {write} (m-1-2)
            (m-2-1.east|-m-2-2) edge node [below] {write} (m-2-2)
            (m-1-2) edge node [left] {l2-to-l1-fs} (m-2-2)
            edge node [below] {read} (m-1-3)
            (m-2-2.east) edge node [below] {read} (m-1-3);
  \end{tikzpicture}
\end{figure}

\section{Some proof details}

We have come to rely on certain principles for the proof effort for
each new model. We summarise these below.

\subsection{Invariants}

As the abstract models grow more complex, with the addition of more
auxiliary data the "sanity" criteria for filesystem instances become more
complex. For instance, in \texttt{L4}, the predicate \texttt{l4-fs-p}
is defined to be the same as \texttt{l3-fs-p}, which recursively
defines the shape of a valid directory tree. However, we choose to
require two more properties for a "sane" filesystem.

\begin{enumerate}
\item Each disk index assigned to a regular file should be
  marked as \textit{used} in the allocation vector - this is essential
  to prevent filesystem errors.
\item Each disk index assigned to a regular file should be distinct
  from all other disk indices assigned to files - this does not hold
  true, for example, in filesystems with hardlinks, but makes our
  proofs easier.
\end{enumerate}

These properties are invariants to be maintained across
write operations; while not all of them are strictly necessary for a
filesystem instance to be valid, they do simplify the verification of
read-after-write properties by helping us ensure that write operations
do not create an "aliasing" situation in which a regular file's
contents can be modified through a write to a different regular file.

These properties, in the form of the predicates
\texttt{indices-marked-listp} and \texttt{no-duplicatesp}, are
packaged together into the \texttt{l4-stricter-fs-p} predicate, for
which a listing follows.

\medskip

\noindent
\begin{verbatim}
(defun l4-stricter-fs-p (fs alv)
  (declare (xargs :guard t))
  (and (l4-fs-p fs)
       (boolean-listp alv)
       (let ((all-indices (l4-list-all-indices fs)))
            (and (no-duplicatesp all-indices)
                 (indices-marked-p all-indices alv)))))
\end{verbatim}

Similarly, we find it useful to package up certain invariants for the
stobj \texttt{fat32-in-memory}, which we maintain while
manipulating the stobj through input/output operations and file
operations, in the predicate \texttt{compliant-fat32-in-memoryp}, for
which a listing follows.

\medskip

\noindent
\begin{verbatim}
(defund compliant-fat32-in-memoryp (fat32-in-memory)
  (declare (xargs :stobjs fat32-in-memory :guard t))
  (and (fat32-in-memoryp fat32-in-memory)
       (>= (bpb_bytspersec fat32-in-memory) *ms-min-bytes-per-sector*)
       (>= (bpb_secperclus fat32-in-memory) 1)
       (>= (count-of-clusters fat32-in-memory)
           *ms-fat32-min-count-of-clusters*)
       (>= (bpb_rootclus fat32-in-memory) *ms-first-data-cluster*)))
\end{verbatim}

\subsection{Reuse}

As noted earlier, in our abstract models, using a refinement
methodology allows us to derive our read-over-write properties
essentially "for free"; more precisely, we are able to prove
read-over-write properties simply with \texttt{:use} hints after
having done the work of proving refinement through induction.

At a lower level, we are also able to benefit from refinement
relationships between components of our different models. For example,
such a relationship exists between the allocation vector used in
\texttt{L4} and the file allocation table used in \texttt{L6}. More
precisely, by taking a file allocation table and mapping each non-zero
entry to \texttt{true} and each zero entry to \texttt{false}, we
obtain a corresponding allocation vector with exactly the same amount
of available space. This is a refinement mapping which makes it a lot
easier to prove that \texttt{L4}, which uses an allocation vector, is
an abstraction of \texttt{L6}, which uses a file allocation
table. This, in turn, means that the effort spent on proving the
invariants described above for \texttt{L4} need not be replicated for
\texttt{L6}.

\section{Co-simulation}

Previous work on executable specifications \cite{goel2014simulation}
has shown the importance of testing these on real examples, in order
to validate that the behaviour shown matches that of the system being
specified. In our case, this means we must validate our filesystem by
testing it in execution against a canonical implementation of FAT32;
in this case, we choose the implementation which ships with Linux
kernel 3.10.

We use \texttt{mkfs.fat}~\cite{hudsonmkfs}, a program which produces
FAT32 disk images, for our tests. When run with the \texttt{-v} flag,
this program emits an English-language summary of the fields of the
newly created disk image; we make use of this by writing an ACL2
program based on our model which reads the image and reproduces this
summary. This validates our code for reading the various fields of the
disk image and gives us a regression test to use while we modify our
model to support proofs and filesystem calls.

Further, we co-simulate \texttt{cat}~\cite{granlundcat}, a simple
program which reads its input and copies it to its output. Its
functionality is reproduced in an ACL2 program which directly
interacts with the \texttt{fat32-in-memory} stobj, without using our
implementations of system calls. This allows us to validate our
code for reading and writing regular files and directories which span
multiple clusters.

%% This stuff is not yet implemented exactly as described.

%% Our first co-simulation test is for \texttt{cat}~\cite{granlundcat}, a
%% simple program which reads its input and copies it to its output. Its
%% functionality is reproduced in an ACL2 program which uses our
%% implementations of the system calls
%% \texttt{lstat}~\cite{kerrisklstat},
%% \texttt{open}~\cite{kerriskopen}, \texttt{pread}~\cite{kerriskpread},
%% \texttt{pwrite}~\cite{kerriskpwrite}, and
%% \texttt{close}~\cite{kerriskclose}. This allows us to validate our
%% code for reading and writing regular files and directories which span
%% multiple clusters.

%% This stuff is not yet implemented at all.

%% We further test the \texttt{dd}~\cite{rubindd} program, which provides
%% similar functionality to \texttt{cat} but with more options to
%% customise the data transfer, for instance, by allowing the data
%% transfer to be split into blocks of a specified size.

\section{Conclusion}

This work formalises a FAT32-like filesystem and proves
read-over-write properties through refinement of a series of
models. Further, it proves the correctness of FAT32's allocation and
garbage collection mechanisms, and provides artefacts to be used in a
subsequent realistic model of FAT32.

\section{Future work}

While FAT32 is interesting of and by itself, it lacks features such as
crash consistency, which most modern filesystems provide by means of
journalling. We hope to re-use some artefacts of formalising FAT32 in
order to verify a filesystem with journalling, such as ext4.

We also hope to model the behaviour of filesystems in a
multiprogramming environment, where concurrent filesystem calls must
be able to occur without corruption or loss of data.
%% Also, we hope to support "code proofs", by providing a basis for
%% reasoning about filesystem operations in filesystem-specific utilities
%% such as \texttt{fsck}, as well as other application programs. This is
%% a large part of the motivation for pursuing binary compatibility.

\subsubsection*{Acknowledgments.} This material is based upon work
supported by the National Science Foundation SaTC program under
contract number CNS-1525472. Thanks are also due to Warren A. Hunt
Jr. and Matthew J. Kaufmann for their guidance.

\section{Bibliography}

\bibliographystyle{eptcs}
\bibliography{references}
\end{document}
